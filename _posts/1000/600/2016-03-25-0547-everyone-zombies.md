---
id: 10002
title: '0547 – &#8220;if everyone were zombies&#8221;'
date: 2016-03-25T18:34:23+00:00
author: visakanv
layout: post
guid: http://visakanv.com/1000/?p=10002
permalink: /0547
readability_ARI:
  - "6.9"
readability_CLI:
  - "8.4"
readability_LIX:
  - "26.8"
word_stats_word_count:
  - "1067"
word_stats_keywords:
  - 's:501:"a:28:{s:11:"interesting";i:4;s:4:"idea";i:5;s:6:"people";i:9;s:6:"glassy";i:3;s:4:"eyed";i:3;s:10:"automatons";i:3;s:5:"think";i:3;s:9:"conscious";i:5;s:5:"human";i:3;s:5:"world";i:5;s:5:"sheep";i:17;s:11:"enlightened";i:3;s:6:"really";i:3;s:7:"thought";i:3;s:4:"feel";i:3;s:7:"because";i:4;s:5:"worry";i:3;s:8:"opinions";i:3;s:6:"social";i:4;s:8:"powerful";i:3;s:7:"perhaps";i:3;s:5:"seems";i:4;s:6:"change";i:3;s:7:"suppose";i:4;s:9:"generally";i:3;s:6:"wouldn";i:6;s:4:"life";i:3;s:6:"pursue";i:3;}";'
word_stats_cached:
  - "1"
categories:
  - Word Vomit
---
It’s interesting to me that so many teenagers develop the idea that nobody understands them, that they’re uniquely self-aware and that (almost) every other person is merely a robotic automaton. It’s amusingly depicted in xkcd 610: Sheeple. “Look at all these people. Glassy-eyed automatons going about their daily lives, never stopping to look around and think! I’m the only conscious human in a world of sheep.”
  
 
  
The inverse idea is presented in some schools of zen or spirituality– that everybody around you is an incredibly enlightened teacher, put on this earth to teach you things that you might not even realise you’re here to be taught. Also an interesting idea. But right now I’m more fascinated by the first one. What if it were somehow true? What if you really WERE the only conscious human in the world? What would the implications be?
  
 
  
The first thought you might have is that you can do absolutely anything you wanted without worrying about what other people thought or cared. You can hurt and abuse people if you feel so inclined– they’re not really people, after all. But this doesn’t nearly work out as well as it might seem. Because while people might be glassy-eyed automatons, they’d still get hurt and upset, and they’d still respond negatively to your abuse. If you commit a crime in a world of sheep, the sheep are still going to punish you for it. So you still have to be mindful of the thoughts and feelings of the sheep.
  
 
  
There’s some nuance there, though. There’s no reason to worry about the sheep laughing at you or mocking you and so on, because you shouldn’t have to be concerned about the opinions of sheep– except when the sheep might choose to cause you harm.
  
 
  
Here’s where it gets a little messy. As a conscious human being, you’re wired to feel emotion, sympathy, shame, guilt– even if you’re surrounded by lesser minds. You’d still enjoy the affection of a puppy, you’d still feel pained witnessing the lonely cries of an abandoned kitten. Those emotions are instinctive, developed over hundreds of thousands of years as social creatures. We were social creatures before we were solitary individuals, and our minds (and bodies?) are designed for it. Herd mentalities are powerful phenomenon. Fear of social ostracisation is a powerful fear. Desire for prestige and social standing is a powerful impulse. These processes continue to function even if we learn that we’re in a world of sheep. Perhaps they might be lessened over time– perhaps we’d learn to recognise the impulses as impulses, and have the space to think about how we actually want to respond.
  
 
  
That seems like a good idea even if we lived in a world of thoughtful, enlightened, conscious beings.
  
 
  
What else would change? Suppose okay, you no longer worry about the opinions of others except when they might be used to cause you harm. You remain a generally friendly person, treating people as you would treat beloved stray animals– you give them space, you speak kindly to them, you’re warm and friendly. But you keep your distance from any that are violent, threatening pro otherwise unpleasant. You find a happy balance. What’s next?
  
 
  
Well, the next thing you might realise is that you can’t count on anybody else’s thinking, because a sheep’s thinking is generally ill-fitted for a conscious being. You might ask for people’s perspective in order to collect data, but you wouldn’t hold anybody else’s opinion as intrinsically more valuable than your own. You might trust an expert (say, an electrician-sheep) because of his expertise in a domain that you’re not familiar with, but you wouldn’t take him seriously when asking him about how to live your life. What you should prioritise, what you should focus on. Unless, perhaps, you ran into a sheep who was living a life that you admired. Suppose you encountered a successful entrepreneur-sheep, or a patriarch-sheep, and you recognized them as living lives that you’d want to emulate. As having circumstances that you’d like for yourself. Then yes, you’d solicit their advice. But again, you wouldn’t hold the advice itself as intrinsically sacred– you’d think “this is what the entrepreneur-sheep said”, and analyse it critically to see if there’s anything that he left out, anything that he misinterpreted and so on.
  
 
  
You especially wouldn’t worry about arguing with sheep in the abstract. You wouldn’t get your hands dirty in sheep forums, unless you were trying to achieve a particular result– trying to elicit a particular response, for example. But you wouldn’t lose sleep over the opinions of sheep. You would see it as all a game, and not be to attached to it.
  
 
  
You would be lonely. Or would you be? Would you ever be fully able to engage with any other being? What is the need or desire to engage with other beings, anyway? Some people have pet dogs and claim that it got rid of their depression. That seems to work. The actual complexity of the mind you’re interacting with is apparently not nearly as important as the seeming sincerity of the affection on display.
  
 
  
What am I even talking about. Why did I pursue this train of thought to begin with? I wanted to figure out if a sincerely solipsistic worldview would change my behaviour or life in any way. Would it make me miserable? I find that the answer is… I really don’t know. It seems improbable that glassy-eyed automatons might be more interesting than me, but it’s clear that there do exist people who are more interesting than me. So rather than pursue “maximum consciousness”, which we have no idea how to measure or verify, we could maybe pursue “maximum interestingness”.  That seems vaguely correct.
  
 
  
What if we went back to the zen question instead? What if everyone were enlightened teachers? How would that change interactions? I suppose it would prompt more engagement, more awareness, more attention from the part of the student.
  
 
  
I suppose that’s probably generally a good thing. So maybe the directive here is simply to be mindful.
  
 